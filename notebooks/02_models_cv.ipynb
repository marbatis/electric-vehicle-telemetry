{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd579c5d",
   "metadata": {},
   "source": [
    "# 02 — Models & CV (Grouped by `cell_id`)\n",
    "\n",
    "Compares multiple models, then a tuned Elastic Net with polynomial features on cells with ≥5 diagnostics.  \n",
    "**Rubric hooks**: multiple appropriate models, cross-validation, tuning, results & analysis, discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5ab7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold, cross_validate, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "CSV='results/rpt_features_labeled_enriched.csv'\n",
    "df=pd.read_csv(CSV).sort_values(['cell_id','diag'], kind='mergesort')\n",
    "\n",
    "src = df['source_file'].astype(str) if 'source_file' in df.columns else (df['cell_id'].astype(str)+'_diag'+df['diag'].astype(str))\n",
    "def parse_rate(s):\n",
    "    m=re.search(r'_([0-9]+(?:_[0-9]+)?)C', s, re.I)\n",
    "    return float(m.group(1).replace('_','.')) if m else np.nan\n",
    "def parse_temp(s):\n",
    "    m=re.search(r'[Tt](\\d{2})', s) or re.search(r'[Nn](\\d{2})', s)\n",
    "    return float(m.group(1)) if m else np.nan\n",
    "if 'c_rate' not in df.columns: df['c_rate']=src.apply(parse_rate)\n",
    "if 'temp_c' not in df.columns: df['temp_c']=src.apply(parse_temp)\n",
    "\n",
    "X = df[['diag','capacity_ah','fade_frac','cap_slope_k3','c_rate','temp_c']].copy()\n",
    "X['c_rate']=X['c_rate'].fillna(0.0)\n",
    "X['temp_c']=X['temp_c'].fillna(X['temp_c'].median() if X['temp_c'].notna().any() else 23.0)\n",
    "X['cap_slope_k3']=X['cap_slope_k3'].fillna(0.0)\n",
    "y = df['RUL'].values\n",
    "groups = df['cell_id'].values\n",
    "\n",
    "def rmse(y_true,y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true,y_pred)))\n",
    "scoring={'rmse': make_scorer(rmse, greater_is_better=False),\n",
    "         'mae': make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "         'r2': 'r2'}\n",
    "cv=GroupKFold(n_splits=min(5, len(np.unique(groups))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be18918",
   "metadata": {},
   "source": [
    "### CV leaderboard (baseline mean, diag-only LR, EN, RF, HGBM, SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46179bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=[]\n",
    "rm,ma,rr=[],[],[]\n",
    "for tr,va in cv.split(X,y,groups=groups):\n",
    "    yhat=np.full_like(y[va], y[tr].mean(), dtype=float)\n",
    "    rm.append(rmse(y[va],yhat))\n",
    "    ma.append(mean_absolute_error(y[va],yhat))\n",
    "    rr.append(r2_score(y[va],yhat))\n",
    "rows.append({'model':'baseline_mean','rmse_mean':np.mean(rm),'rmse_std':np.std(rm),\n",
    "             'mae_mean':np.mean(ma),'mae_std':np.std(ma),'r2_mean':np.mean(rr)})\n",
    "\n",
    "pipe_lr = Pipeline([('scaler',StandardScaler()),('lr',LinearRegression())])\n",
    "cvres = cross_validate(pipe_lr, df[['diag']], y, groups=groups, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "rows.append({'model':'linear_diag_only','rmse_mean':-np.mean(cvres['test_rmse']),\n",
    "             'rmse_std':np.std(-cvres['test_rmse']),\n",
    "             'mae_mean':-np.mean(cvres['test_mae']),'mae_std':np.std(-cvres['test_mae']),\n",
    "             'r2_mean':np.mean(cvres['test_r2'])})\n",
    "\n",
    "models={\n",
    " 'elastic_net':Pipeline([('scaler',StandardScaler()),('enet',ElasticNet(alpha=0.01,l1_ratio=0.2,max_iter=8000,random_state=42))]),\n",
    " 'random_forest':RandomForestRegressor(n_estimators=500,random_state=42,n_jobs=-1),\n",
    " 'hist_gbm':HistGradientBoostingRegressor(random_state=42),\n",
    " 'svr_rbf':Pipeline([('scaler',StandardScaler()),('svr',SVR(kernel='rbf',C=10,gamma=0.001,epsilon=0.2))]),\n",
    "}\n",
    "for name,mdl in models.items():\n",
    "    cvres = cross_validate(mdl, X, y, groups=groups, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    rows.append({'model':name,'rmse_mean':-np.mean(cvres['test_rmse']),\n",
    "                 'rmse_std':np.std(-cvres['test_rmse']),\n",
    "                 'mae_mean':-np.mean(cvres['test_mae']),'mae_std':np.std(-cvres['test_mae']),\n",
    "                 'r2_mean':np.mean(cvres['test_r2'])})\n",
    "lb=pd.DataFrame(rows).sort_values('rmse_mean')\n",
    "os.makedirs('results', exist_ok=True)\n",
    "lb.to_csv('results/leaderboard.csv', index=False)\n",
    "lb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ff7aac",
   "metadata": {},
   "source": [
    "### Tuned Elastic Net (poly) on cells with ≥5 diagnostics + OOF metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e6470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=df.groupby('cell_id')['diag'].nunique()\n",
    "keep=cnt[cnt>=5].index\n",
    "df_f=df[df['cell_id'].isin(keep)].copy()\n",
    "\n",
    "df_f['diag_norm']=df_f['diag']/df_f.groupby('cell_id')['diag'].transform('max')\n",
    "df_f['cap_pct']=df_f['capacity_ah']/df_f.groupby('cell_id')['capacity_ah'].transform('first')\n",
    "\n",
    "Xf=df_f[['diag','diag_norm','capacity_ah','cap_pct','fade_frac','cap_slope_k3','c_rate','temp_c']].copy()\n",
    "Xf['cap_slope_k3']=Xf['cap_slope_k3'].fillna(0.0)\n",
    "yf=df_f['RUL'].values\n",
    "gf=df_f['cell_id'].values\n",
    "\n",
    "pipe=Pipeline([('poly',PolynomialFeatures(2, include_bias=False)),('scaler',StandardScaler()),('enet',ElasticNet(max_iter=15000,random_state=42))])\n",
    "param_grid={'enet__alpha':np.logspace(-3,1,15),'enet__l1_ratio':[0.05,0.2,0.5,0.8]}\n",
    "cv2=GroupKFold(n_splits=min(5,len(np.unique(gf))))\n",
    "scorer=make_scorer(lambda yt,yp: float(np.sqrt(mean_squared_error(yt,yp))), greater_is_better=False)\n",
    "search=GridSearchCV(pipe, param_grid, cv=cv2, scoring=scorer, n_jobs=-1, refit=True)\n",
    "search.fit(Xf,yf,groups=gf)\n",
    "print('Best params:', search.best_params_, 'CV RMSE:', -search.best_score_)\n",
    "\n",
    "oof=np.full_like(yf, np.nan, dtype=float)\n",
    "for tr,va in cv2.split(Xf,yf,groups=gf):\n",
    "    model=search.best_estimator_\n",
    "    model.fit(Xf.iloc[tr], yf[tr])\n",
    "    oof[va]=model.predict(Xf.iloc[va])\n",
    "\n",
    "def rmse_fn(yt,yp):\n",
    "    return float(np.sqrt(mean_squared_error(yt,yp)))\n",
    "\n",
    "oof_rmse=rmse_fn(yf,oof)\n",
    "oof_mae=mean_absolute_error(yf,oof)\n",
    "oof_r2=r2_score(yf,oof)\n",
    "print(f'OOF (filtered, tuned) — RMSE={oof_rmse:.3f}, MAE={oof_mae:.3f}, R^2={oof_r2:.3f}')\n",
    "\n",
    "per_cell=(pd.DataFrame({'cell_id':df_f['cell_id'],'y':yf,'oof':oof})\n",
    "            .groupby('cell_id')\n",
    "            .apply(lambda g: pd.Series({\n",
    "                'rmse':rmse_fn(g['y'],g['oof']),\n",
    "                'mae':mean_absolute_error(g['y'],g['oof']),\n",
    "                'r2':r2_score(g['y'],g['oof'])\n",
    "            })).reset_index())\n",
    "per_cell.to_csv('results/per_cell_oof_metrics_tuned.csv', index=False)\n",
    "\n",
    "plt.figure(dpi=120)\n",
    "plt.scatter(yf,oof,s=24,alpha=0.7)\n",
    "lo,hi=float(min(np.nanmin(yf),np.nanmin(oof))), float(max(np.nanmax(yf),np.nanmax(oof)))\n",
    "plt.plot([lo,hi],[lo,hi],'k--')\n",
    "plt.xlabel('True RUL')\n",
    "plt.ylabel('Predicted RUL (OOF)')\n",
    "plt.title('Parity — Elastic Net (poly, filtered)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figs/parity_plot_oof_tuned.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
